from collections import Counter
import re

def analyze_text(file_name, num_top_words):
    # Читаем текстовый файл
    with open(file_name, 'r', encoding='utf-8') as file:
        text = file.read()

    # Разбиваем текст на слова, учитывая только буквенные символы
    words = re.findall(r'\b\w+\b', text.lower())

    # Создаем словарь частотности слов
    word_counts = Counter(words)

    # Выводим наиболее часто встречающиеся слова
    print(f"Список {num_top_words} наиболее часто встречающихся слов в файле {file_name}:")
    for word, count in word_counts.most_common(num_top_words):
        print(f"{word}: {count} раз")

# Укажите путь к текстовому файлу и количество слов для анализа
file_name = "text_data.txt"
num_top_words = 10

analyze_text(file_name, num_top_words)